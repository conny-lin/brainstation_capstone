{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trinity worm data from 0mM and 400mM N2\n",
    "# Conny Lin | June 3, 2020\n",
    "# connylin@doctor.com\n",
    "#\n",
    "# combine all trinity within a plate into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to each plate --\n",
    "# load pickle\n",
    "plateDB = pickle.load(open(os.path.join(dir_save, 'file_summary_mwt.pickle'),'rb'))\n",
    "# get paths with trinity.id.dat\n",
    "pMWT = plateDB.index[~plateDB[('filepath','trinity.id.dat')].isna()].values\n",
    "\n",
    "col_ind_keep = [0,3,5,6,8,9,10,11,12,13,14,15,16,17]\n",
    "# load column names legend\n",
    "p = os.path.join(dir_save, 'legend_trinity_worm.pickle')\n",
    "cnames = pickle.load(open(p,'rb'))\n",
    "cnames = cnames['name'].values\n",
    "cnames_keep = cnames[col_ind_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/COBOLT/MWT/20140810A_SJ_100s30x60s10s_glr1_60s/VM3109/20140810_122010\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7e747cad3d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mplate_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpPlate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpMWT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstarting_plate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstarting_plate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpPlate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'processing {plate_count}/{pMWT.shape[0]} plate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# find all trinity files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: stop"
     ]
    }
   ],
   "source": [
    "# go in each plate\n",
    "# for p in pMWT:\n",
    "starting_plate = 425\n",
    "for plate_count, pPlate in enumerate(pMWT[starting_plate:],starting_plate+1):\n",
    "    print(pPlate)\n",
    "    print(f'processing {plate_count}/{pMWT.shape[0]} plate')\n",
    "    # find all trinity files\n",
    "    ptri = glob.glob(pPlate+\"/*.trinity.*.dat\")\n",
    "    # print number of files\n",
    "    print(f'\\t{len(ptri)} trinity files in this plate')\n",
    "\n",
    "\n",
    "    # get worm id from filep path\n",
    "    df = pd.DataFrame({'paths':ptri})\n",
    "    worm_number = df['paths'].str.extract(r'(?<=trinity[.])(\\d{1,})')\n",
    "    worm_number = worm_number.astype('int32').values\n",
    "\n",
    "    # get number of rows per doc\n",
    "    # declare empty array to store the row numbers\n",
    "    rows_array = np.empty((len(ptri)),dtype='int')\n",
    "    # loop through each files \n",
    "    for i, p in enumerate(ptri, 0):\n",
    "        # report process every 100 files\n",
    "        if (i%100==0):\n",
    "            print(f'\\tprocessing #{i} files', end='\\r')\n",
    "        # create custom bash command\n",
    "        bashCommand = \"cat \"+p+\" | wc -l\"\n",
    "        # call bash\n",
    "        output = subprocess.check_output(bashCommand, shell=True)\n",
    "        # take out digits from the byte output\n",
    "        rows_array[i] = int(output)\n",
    "\n",
    "\n",
    "    # create worm id array\n",
    "    # get info\n",
    "    row_total = rows_array.sum()\n",
    "    # instantiate arrays\n",
    "    row_repeats_array = np.empty([row_total], dtype='int')\n",
    "    # create arrays\n",
    "    i_row_previous = 0\n",
    "    for worm_id, rows in zip(worm_number, rows_array):\n",
    "        # get start row position\n",
    "        i_start_row = i_row_previous\n",
    "        # get end row position\n",
    "        i_end_row = i_row_previous+rows-1\n",
    "        # get worm id array x number of rows\n",
    "        row_repeats_array[i_start_row:i_end_row+1] = np.tile(worm_id, rows)\n",
    "        # create next starting position\n",
    "        i_row_previous = rows+i_row_previous\n",
    "    \n",
    "    \n",
    "    # concat paths (process by 1000/batch)\n",
    "    # copy path file for trimming\n",
    "    ptri_bash = ptri.copy()\n",
    "    psave_trinity_list = []\n",
    "    # while pathfile still has stuff in it\n",
    "    while len(ptri) > 0:\n",
    "        ptri_len = len(ptri_bash)\n",
    "        ptri_bash_process = ptri_bash[:1000].copy()\n",
    "        ptri_bash = ptri_bash[1000:].copy()\n",
    "\n",
    "        bashcommand_sourcepaths = ''\n",
    "        for p in ptri_bash_process:\n",
    "            p = \"'\"+p+\"'\"\n",
    "            bashcommand_sourcepaths += p\n",
    "            bashcommand_sourcepaths += ' '\n",
    "        # create bash command components\n",
    "        n_files = len(psave_trinity_list)\n",
    "        psave_trinity = os.path.join(pPlate, f'temp_trinity{n_files}.dat')\n",
    "        bashcommand = 'cat ' + bashcommand_sourcepaths + '> ' + \"'\"+ psave_trinity + \"'\"\n",
    "        psave_trinity_list.append(psave_trinity)\n",
    "        print(f'\\tslice process trinity: {psave_trinity}')\n",
    "        # call bash command\n",
    "        os.system(bashcommand)\n",
    "\n",
    "    # cat temp trinity files\n",
    "    psave_trinity = os.path.join(pPlate, 'temp_trinity.dat')\n",
    "    if len(psave_trinity_list)>0:\n",
    "        bashcommand_sourcepaths = ''\n",
    "        for p in psave_trinity_list:\n",
    "            p = \"'\"+p+\"'\"\n",
    "            bashcommand_sourcepaths += p\n",
    "            bashcommand_sourcepaths += ' '\n",
    "        bashcommand = 'cat ' + bashcommand_sourcepaths + '> ' + \"'\"+ psave_trinity + \"'\"\n",
    "        os.system(bashcommand)\n",
    "        # remove files\n",
    "        for p in psave_trinity_list:\n",
    "            os.remove(p)\n",
    "        print('\\tcombine slice processed trinity')\n",
    "\n",
    "    # load tirnity concatenated\n",
    "    df = pd.read_csv(psave_trinity, delim_whitespace=True, header=None, usecols=col_ind_keep, names=cnames_keep)\n",
    "    # break out of this loop if wormid array are not the same size as the concatenated array\n",
    "    if df.shape[0] != row_repeats_array.shape[0]:\n",
    "        # print warning\n",
    "        array_dff = df.shape[0] - row_repeats_array.shape[0]\n",
    "        print(f'\\t!!wormid array has {array_dff} rows of the trinity data')    \n",
    "        continue\n",
    "\n",
    "    # add wormid field\n",
    "    df['wormid'] = row_repeats_array\n",
    "    # into pickle\n",
    "    psave_pickle = os.path.join(pPlate, 'trinity_all_worms.pickle')\n",
    "    # save pickle\n",
    "    pickle.dump(df, open(psave_pickle,'wb'))\n",
    "    \n",
    "    # check if pickle file saved\n",
    "    if os.path.exists(psave_pickle):\n",
    "        # report size of the output\n",
    "        size_trinity = os.path.getsize(psave_pickle)\n",
    "        print(f'\\tsize of pickle file: {size_trinity/1000**2:.0f} MB')\n",
    "    else:\n",
    "        print('\\tpickle file did not save')\n",
    "    \n",
    "    # clean up temp files\n",
    "    if os.path.exists(psave_trinity):\n",
    "        print('\\tclean up trinity temp file')\n",
    "        os.remove(psave_trinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
