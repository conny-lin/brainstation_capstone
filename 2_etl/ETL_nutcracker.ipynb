{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETL nutcracker\n",
    "# Conny Lin | June 6, 2020\n",
    "# transform data from raw to ML ready data\n",
    "# code below have been added to BrainStationLib.py\n",
    "# also saved in ETL_nutcracker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local variable setting\n",
    "pCapstone = '/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data'\n",
    "pDropboxdb = '/Users/connylin/Dropbox/MWT/db'\n",
    "pCobolt = '/Volumes/COBOLT'\n",
    "mwtpath_csv_name_cobolt = 'mwtpath_cobolt.csv'\n",
    "mwtpath_csv_name_dropbox = 'mwtpath_dropbox.csv'\n",
    "\n",
    "# UPDATE THESE SETTINGS\n",
    "sourcedir_db = pDropboxdb\n",
    "savedir_db = pDropboxdb\n",
    "savedir = pCapstone\n",
    "mwtpath_csv_name = mwtpath_csv_name_dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, sys, glob, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import local functions\n",
    "sys.path.insert(1, '/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/brainstation_capstone/0_lib')\n",
    "import BrainStationLib as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mwtpath.csv from \n",
      "\t/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data/mwtpath_dropbox.csv\n",
      "7294 mwt folders found\n"
     ]
    }
   ],
   "source": [
    "pathcsv = os.path.join(pCapstone, mwtpath_csv_name)\n",
    "if os.path.isfile(pathcsv):\n",
    "    print(f'loading mwtpath.csv from \\n\\t{pathcsv}')\n",
    "    df = pd.read_csv(pathcsv)\n",
    "    mwtpaths = df['mwtpath'].values\n",
    "else:\n",
    "    mwtpaths = glob.glob(sourcedir_db+'/*/*/*/[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]_[0-9][0-9][0-9][0-9][0-9][0-9]')\n",
    "    print(f'saving mwtpath found to \\n\\t{pathcsv}')\n",
    "    df = pd.DataFrame({'mwtpath':mwtpaths})\n",
    "    df.to_csv(pathcsv)\n",
    "print(f'{len(mwtpaths)} mwt folders found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/connylin/Dropbox/MWT/db/MWT/20111114C_CL_100s30x10s10s/N2_400mM/20111114_141722\n",
      "\tprocessing 192\n",
      "\t66924 rows\n",
      "\tsaved nutcracker_100s.csv\n",
      "/Users/connylin/Dropbox/MWT/db/MWT/20111114C_CL_100s30x10s10s/N2/20111114_142532\n",
      "\tprocessing 295\n",
      "\t83976 rows\n",
      "\tsaved nutcracker_100s.csv\n",
      "/Users/connylin/Dropbox/MWT/db/MWT/20111114C_CL_100s30x10s10s/N2/20111114_140917\n",
      "\tprocessing 143\n",
      "\t89038 rows\n",
      "\tsaved nutcracker_100s.csv\n"
     ]
    }
   ],
   "source": [
    "# combine individual nutcracker per plate\n",
    "_, nutcracker_filepaths = bs.nutcracker_process_perplate(mwtpaths, sourcedir_db, savedir_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combne all combined nutcracker data from each plate (memory intensive!)\n",
    "data = bs.nutcracker_combineall(nutcracker_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving done\n"
     ]
    }
   ],
   "source": [
    "# split into X y data set and save to dropbox (large file! 20GB expected)\n",
    "bs.nutcracker_split_Xy(data, savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\there:/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data\n"
     ]
    }
   ],
   "source": [
    "print('\\there:'+savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "code end here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e76d21b9b13d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code end here'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# below are development notes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: code end here"
     ]
    }
   ],
   "source": [
    "assert False, 'code end here'\n",
    "# below are development notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make legend\n",
    "pchorelegend = os.path.join(pCapstone, 'legend_choreography.csv')\n",
    "chorjavacall = 'tDfpemMwWlLaAkcsSbpdxyuvor1234'\n",
    "chorelegend = bs.make_chor_output_legend(pchorelegend, chorjavacall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chorjavacall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persistence data is duplicated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chorelegend['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preselect columns to load\n",
    "column_index_keep = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19,22,23,24,25]\n",
    "column_names = chorelegend['name'][column_index_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: look for data in db\n",
    "# TODO: change pDropboxdb to pCobolt\n",
    "mwtpaths_db = glob.glob(pDropboxdb+'/*/*/*/[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]_[0-9][0-9][0-9][0-9][0-9][0-9]')\n",
    "print(f'{len(mwtpaths_db)} mwt folders found')\n",
    "# save this\n",
    "df = pd.DataFrame({'mwtpath':mwtpaths_db})\n",
    "df.to_csv(os.path.join(pCapstone, 'mwtpath.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nutcracker_process_rawdata(pdata, mwtid):\n",
    "    column_names_raw = ['time','id','frame','persistence','area','midline','morphwidth',\n",
    "                        'width','relwidth','length','rellength','aspect','relaspect',\n",
    "                        'kink','curve','speed','angular','bias','persistence','dir',\n",
    "                        'loc_x','loc_y','vel_x','vel_y','orient','crab','tap','puff',\n",
    "                        'stim3','stim4']  \n",
    "    column_index_keep = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19,22,23,24,25]\n",
    "    # load data put in data frame\n",
    "    df = pd.read_csv(pdata, delimiter=' ', header=None, usecols=column_index_keep, \n",
    "                     names=column_names, dtype=np.float64, engine='c')\n",
    "    # remove data before 100s\n",
    "    df.drop(axis=0, index=df.index[df['time']>100], inplace=True)\n",
    "    # remove nan\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    # add mwtid column\n",
    "    df.insert(0,'mwtid', np.tile(mwtid, df.shape[0]))\n",
    "    # add etoh column\n",
    "    if ('/N2_400mM/' in pdata):\n",
    "        df.insert(0,'etoh', np.tile(1, df.shape[0]))\n",
    "    else:\n",
    "        df.insert(0,'etoh', np.tile(0, df.shape[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nutcracker_pick_consolidate_data(mwtpaths_db, pCobolt, pDropboxdb):\n",
    "    # look for nutcracker files in this plate\n",
    "    nutcracker_filelist = []\n",
    "    for imwt, pmwt in enumerate(mwtpaths_db):\n",
    "        pnutcracker = glob.glob(pmwt+'/*.nutcracker.*.dat')\n",
    "        if len(pnutcracker) > 0:\n",
    "            print(pmwt)\n",
    "            # make storage for df\n",
    "            df_store = []\n",
    "            for ifile, pdata in enumerate(pnutcracker):\n",
    "                print(f'\\tprocessing {ifile}', end='\\r')\n",
    "                # get time data\n",
    "                df = pd.read_csv(pdata, delimiter=' ', header=None, usecols=[0], \n",
    "                                 names=['time'], dtype=np.float64, engine='c')\n",
    "                # see if data has time before 100s\n",
    "                if sum(df['time']<100) > 0:\n",
    "                    df = nutcracker_process_rawdata(pdata, imwt)\n",
    "                    # add df to storage\n",
    "                    df_store.append(df)\n",
    "            # combine multiple nutcracker files (just before tap and only non NAN)\n",
    "            df_mwt = pd.concat(df_store, ignore_index=True)\n",
    "            print(f'\\n\\t{df_mwt.shape[0]} rows')\n",
    "            # add etoh column\n",
    "\n",
    "            # save csv in dropbox\n",
    "            pmwt_dropbox = str.replace(pmwt, pCobolt, pDropboxdb)\n",
    "            pdata_save_dropbox = os.path.join(pmwt_dropbox, 'nutcracker_100s.csv')\n",
    "            nutcracker_filelist.append(pdata_save_dropbox)\n",
    "            df_mwt.to_csv(pdata_save_dropbox, index=False)\n",
    "            print(f'\\tsaved nutcracker_100s.csv')\n",
    "    return df_mwt, nutcracker_filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimate data size: 33.1*1500/1000 = 50GB - more reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mwt, nutcracker_filelist = nutcracker_pick_consolidate_data(mwtpaths_db, pCobolt, pDropboxdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate number of rows at the end\n",
    "print('estimate of total rows without data reduction')\n",
    "print(int((239938 / 3 * 1400) * (5*60/90) * (8000/1400)))\n",
    "print('estimate of total rows with data reduction')\n",
    "print(int((239938 / 3 * 1400)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nutcracker_combine(nutcracker_filepaths)\n",
    "    # load and combine nutcracker_filelist\n",
    "    df_store = []\n",
    "    for filepath in nutcracker_filepaths:\n",
    "        df_store.append(pd.read_csv(filepath, dtype=np.float64, engine='c'))\n",
    "    data = pd.concat(df_store, ignore_index=True)\n",
    "    return data\n",
    "\n",
    "data = nutcracker_combine(nutcracker_filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "size_file = int(sys.getsizeof(data)/1000**3/len(df_store)*1400)\n",
    "print(f'estimate end size {size_file:.2f} GB')\n",
    "del df_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nutcracker_split_Xy(data, dir_save)\n",
    "    # split X/y\n",
    "    # y column\n",
    "    y_column = ['etoh']\n",
    "    y = data[y_column].copy()\n",
    "    data.drop(columns=y_column, inplace=True)\n",
    "    y.to_csv(os.path.join(dir_save, 'nutcracker_y.csv'), index=False)\n",
    "    # identifier column\n",
    "    identifier_column = ['id','mwtid']\n",
    "    data_identifiers = data[identifier_column].copy()\n",
    "    data.drop(columns=identifier_column, inplace=True)\n",
    "    data_identifiers.to_csv(os.path.join(dir_save, 'nutcracker_identifier.csv'), index=False)\n",
    "    # save X\n",
    "    data.to_csv(os.path.join(dir_save, 'nutcracker_X.csv'), index=False)\n",
    "    print('saving done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
