{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL trinity data\n",
    "# Conny Lin | June 4, 2020\n",
    "\n",
    "# prepare the data into machine learning ready format.\n",
    "# Extract data from individual plates, label with plate index in the plate db, and group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global varialbes/paths\n",
    "dir_save = '/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make data db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file pickle\n",
    "plateDB = pickle.load(open(os.path.join(dir_save, 'file_summary_mwt.pickle'),'rb'))\n",
    "# get paths with trinity.id.dat\n",
    "pMWT = plateDB.index[~plateDB[('filepath','trinity.id.dat')].isna()].values\n",
    "del plateDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "MWTDB = pd.DataFrame({'mwtpath':pMWT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/871 files exist\n"
     ]
    }
   ],
   "source": [
    "# take a look at the db to see if any missing trinity pickle \n",
    "# instantiate \n",
    "report_capture = np.zeros(len(pMWT),dtype='bool')\n",
    "for plateid, pPlate in enumerate(MWTDB['mwtpath']):\n",
    "    # get expected apth to trinity data\n",
    "    pfile = os.path.join(pPlate, 'trinity_all_worms.pickle')\n",
    "    # see if file exist\n",
    "    if os.path.exists(pfile):\n",
    "        report_capture[plateid] = True\n",
    "    else:\n",
    "        print(f'{plateid} does not exist', end='\\r')\n",
    "\n",
    "# report result\n",
    "print(f'{np.sum(report_capture)}/{len(report_capture)} files exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the plate that failed to concatenate trinity\n",
    "MWTDB.drop(index=MWTDB.index[~report_capture].values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MWTDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths to trinitu files\n",
    "MWTDB['trinity_path'] = list(map(lambda x: os.path.join(x,'trinity_all_worms.pickle'), MWTDB['mwtpath']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "MWTDB.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract experiment features\n",
    "df = MWTDB['mwtpath'].str.split(pat='/', expand=True)\n",
    "MWTDB['expname'] = df.iloc[:,4]\n",
    "MWTDB['groupname'] = df.iloc[:,5]\n",
    "MWTDB['platename'] = df.iloc[:,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows per pickle file\n",
    "# note some trinity files may not be converted to pickle files. Instead of checking availability, \n",
    "# random choose 1.1M numbers and then use only first 1M rows that has files\n",
    "pickle_rows = np.zeros(MWTDB.shape[0], dtype='int')\n",
    "for i, p in enumerate(MWTDB['trinity_path']):\n",
    "    if i%5==0:\n",
    "        print(f'getting row numbers from {i}th file', end='\\r')\n",
    "    df = pd.read_pickle(p)\n",
    "    pickle_rows[i] = df.shape[0]\n",
    "MWTDB['rows'] = pickle_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dropbox save folder, mkdir if not exist\n",
    "pDropbox_home = '/Users/connylin/Dropbox/MWT/db'\n",
    "pReplace = '/Volumes/COBOLT'\n",
    "# replace path \n",
    "MWTDB['mwtpath_dropbox'] = list(map(lambda p: p.replace(pReplace, pDropbox_home), MWTDB['mwtpath']))\n",
    "MWTDB['trinity_path_dropbox'] = list(map(lambda p: p.replace(pReplace, pDropbox_home), MWTDB['trinity_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save database\n",
    "pickle.dump(MWTDB, open(os.path.join(dir_save, 'MWTDB_trinity_N2400mM.pickle'),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add labels to individual plate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plateid 869 dropped 7112 rows to 162496 rowssss\r"
     ]
    }
   ],
   "source": [
    "# take a sample to see if need per file processing\n",
    "for ind in MWTDB.index.values:\n",
    "    # get path\n",
    "    ptrinity = MWTDB['trinity_path'].iloc[ind]\n",
    "    # load to dataframe\n",
    "    df = pickle.load(open(ptrinity,'rb'))\n",
    "    row_n_original = df.shape[0]\n",
    "    # check if the data already been cleaned\n",
    "    if any(df.columns=='mwtid_trdb'):\n",
    "        continue\n",
    "    # clean nan data\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    row_n_after = df.shape[0]\n",
    "    print(f'plateid {ind} dropped {row_n_original - row_n_after} rows to {row_n_after} rows', end='\\r')\n",
    "    # add file path \n",
    "    df.insert(0,'mwtid_trdb', np.tile(MWTDB.index[ind], df.shape[0]))\n",
    "    # add group id (ethanol=1 vs no ethanol=0)\n",
    "    if MWTDB['groupname'][ind]=='N2':\n",
    "        df.insert(1,'etoh', np.tile(0, df.shape[0]))\n",
    "    else:\n",
    "        df.insert(1,'etoh', np.tile(1, df.shape[0]))\n",
    "    # save the file\n",
    "    pickle.dump(df, open(ptrinity,'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat all trinity data\n",
    "https://stackoverflow.com/questions/56012595/how-to-pickle-multiple-pandas-dataframes-and-concatenate-all-of-them-i\n",
    "\n",
    "```\n",
    "df = pd.concat([pd.read_pickle('/PATH/df/{}/{}.F.K.df'.format('train', f)).iloc[:, :100] \n",
    "                for f in Files], \n",
    "               axis=1)\n",
    "```\n",
    "\n",
    "`a = [pd.read_pickle(p) for p in MWTDB['trinity_path'][:10]]`\n",
    "\n",
    "Issues:\n",
    "\n",
    "* Each csv is ~100MB * 800 = 80GB csv. My computer won't be able to open this file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can I predict which tap number the worm is reacting to by it's behavior before and after the tap?\n",
    "* for wildtype\n",
    "* for ethanol vs non ethanol\n",
    "* for mutants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at  behavior and see if can predict which tap it is\n",
    "MWTDB = pickle.load(open(os.path.join(dir_save, 'MWTDB_trinity_N2400mM.pickle'),'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach 1 random 10 plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 10 plates of 0mM and 10 plates of 400mM to look at\n",
    "np.random.seed(318)\n",
    "ind_0mM = np.random.choice(MWTDB.index[MWTDB['groupname']=='N2'].values, 10, replace=False)\n",
    "ind_400mM = np.random.choice(MWTDB.index[MWTDB['groupname']=='N2_400mM'].values, 10, replace=False)\n",
    "# combine index from 0mM and 400mM\n",
    "i = np.hstack((ind_0mM, ind_400mM))\n",
    "# get trininty file paths from random samples\n",
    "ptrinity = MWTDB['trinity_path'].iloc[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.concat([pd.read_pickle(p) for p in ptrinity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11894033 entries, 1 to 1579776\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   mwtid_trdb  int64  \n",
      " 1   etoh        int64  \n",
      " 2   time        float64\n",
      " 3   speed       float64\n",
      " 4   bias        float64\n",
      " 5   tap         float64\n",
      " 6   loc_x       float64\n",
      " 7   loc_y       float64\n",
      " 8   morphwidth  float64\n",
      " 9   midline     float64\n",
      " 10  area        float64\n",
      " 11  angular     float64\n",
      " 12  aspect      float64\n",
      " 13  kink        float64\n",
      " 14  curve       float64\n",
      " 15  crab        float64\n",
      " 16  wormid      int64  \n",
      "dtypes: float64(14), int64(3)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach 2, random 1 million rows from each group\n",
    "\n",
    "* 20 plates gives 11,894,033 rows of data. 800/20 = 40*12M = 480M rows of data\n",
    "* 300s*20 frame per sec = 6000 time points. 1M rows would have 1000/6 = 500/3 = 166 samples per time point. Will start with this and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of rows per trinity file\n",
    "df = pd.read_pickle(os.path.join(dir_save, 'fileinfo_trinity_N2400mM.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows: 202718463\n"
     ]
    }
   ],
   "source": [
    "# get sum\n",
    "row_total = df['row_number'].sum()\n",
    "print(f'total number of rows: {row_total}')\n",
    "# randomly choose between those numbers\n",
    "# get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      /Volumes/COBOLT/MWT/20110906B_CL_100s30x60s10s...\n",
       "1      /Volumes/COBOLT/MWT/20110906B_CL_100s30x60s10s...\n",
       "2      /Volumes/COBOLT/MWT/20110906B_CL_100s30x60s10s...\n",
       "3      /Volumes/COBOLT/MWT/20110907B_SS_100s30x10s10s...\n",
       "4      /Volumes/COBOLT/MWT/20110907B_SS_100s30x10s10s...\n",
       "                             ...                        \n",
       "865    /Volumes/COBOLT/MWT/20170605X_CR_100s30x10s10s...\n",
       "866    /Volumes/COBOLT/MWT/20170605X_CR_100s30x10s10s...\n",
       "867    /Volumes/COBOLT/MWT/20170605X_CR_100s30x10s10s...\n",
       "868    /Volumes/COBOLT/MWT/20170605X_CR_100s30x10s10s...\n",
       "869    /Volumes/COBOLT/MWT/20170605X_CR_100s30x10s10s...\n",
       "Name: trinity_path, Length: 870, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MWTDB['trinity_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
