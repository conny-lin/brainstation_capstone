{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trinity worm data from 0mM and 400mM N2\n",
    "# Conny Lin | June 3, 2020\n",
    "# connylin@doctor.com\n",
    "#\n",
    "# combine all trinity within a plate into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to each plate --\n",
    "# load pickle\n",
    "plateDB = pickle.load(open(os.path.join(dir_save, 'file_summary_mwt.pickle'),'rb'))\n",
    "# get paths with trinity.id.dat\n",
    "pMWT = plateDB.index[~plateDB[('filepath','trinity.id.dat')].isna()].values\n",
    "\n",
    "col_ind_keep = [0,3,5,6,8,9,10,11,12,13,14,15,16,17]\n",
    "# load column names legend\n",
    "p = os.path.join(dir_save, 'legend_trinity_worm.pickle')\n",
    "cnames = pickle.load(open(p,'rb'))\n",
    "cnames = cnames['name'].values\n",
    "cnames_keep = cnames[col_ind_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go in each plate\n",
    "# for p in pMWT:\n",
    "starting_plate = 425\n",
    "for plate_count, pPlate in enumerate(pMWT[starting_plate:],starting_plate+1):\n",
    "    print(f'processing {plate_count}/{pMWT.shape[0]} plate')\n",
    "    # find all trinity files\n",
    "    ptri = glob.glob(pPlate+\"/*.trinity.*.dat\")\n",
    "    # print number of files\n",
    "    print(f'\\t{len(ptri)} trinity files in this plate')\n",
    "\n",
    "\n",
    "    # get worm id from filep path\n",
    "    df = pd.DataFrame({'paths':ptri})\n",
    "    worm_number = df['paths'].str.extract(r'(?<=trinity[.])(\\d{1,})')\n",
    "    worm_number = worm_number.astype('int32').values\n",
    "\n",
    "    # get number of rows per doc\n",
    "    # declare empty array to store the row numbers\n",
    "    rows_array = np.empty((len(ptri)),dtype='int')\n",
    "    # loop through each files \n",
    "    for i, p in enumerate(ptri, 0):\n",
    "        # report process every 100 files\n",
    "        if (i%100==0):\n",
    "            print(f'\\tprocessing #{i} files', end='\\r')\n",
    "        # create custom bash command\n",
    "        bashCommand = \"cat \"+p+\" | wc -l\"\n",
    "        # call bash\n",
    "        output = subprocess.check_output(bashCommand, shell=True)\n",
    "        # take out digits from the byte output\n",
    "        rows_array[i] = int(output)\n",
    "\n",
    "\n",
    "    # create worm id array\n",
    "    # get info\n",
    "    row_total = rows_array.sum()\n",
    "    # instantiate arrays\n",
    "    row_repeats_array = np.empty([row_total], dtype='int')\n",
    "    # create arrays\n",
    "    i_row_previous = 0\n",
    "    for worm_id, rows in zip(worm_number, rows_array):\n",
    "        # get start row position\n",
    "        i_start_row = i_row_previous\n",
    "        # get end row position\n",
    "        i_end_row = i_row_previous+rows-1\n",
    "        # get worm id array x number of rows\n",
    "        row_repeats_array[i_start_row:i_end_row+1] = np.tile(worm_id, rows)\n",
    "        # create next starting position\n",
    "        i_row_previous = rows+i_row_previous\n",
    "    \n",
    "    \n",
    "    # concat paths (process by 1000/batch)\n",
    "    # copy path file for trimming\n",
    "    ptri_bash = ptri.copy()\n",
    "    psave_trinity_list = []\n",
    "    # while pathfile still has stuff in it\n",
    "    while len(ptri) > 0:\n",
    "        ptri_len = len(ptri_bash)\n",
    "        ptri_bash_process = ptri_bash[:1000].copy()\n",
    "        ptri_bash = ptri_bash[1000:].copy()\n",
    "\n",
    "        bashcommand_sourcepaths = ''\n",
    "        for p in ptri_bash_process:\n",
    "            p = \"'\"+p+\"'\"\n",
    "            bashcommand_sourcepaths += p\n",
    "            bashcommand_sourcepaths += ' '\n",
    "        # create bash command components\n",
    "        n_files = len(psave_trinity_list)\n",
    "        psave_trinity = os.path.join(pPlate, f'temp_trinity{n_files}.dat')\n",
    "        bashcommand = 'cat ' + bashcommand_sourcepaths + '> ' + \"'\"+ psave_trinity + \"'\"\n",
    "        psave_trinity_list.append(psave_trinity)\n",
    "        print(f'\\tslice process trinity: {psave_trinity}')\n",
    "        # call bash command\n",
    "        os.system(bashcommand)\n",
    "\n",
    "    # cat temp trinity files\n",
    "    psave_trinity = os.path.join(pPlate, 'temp_trinity.dat')\n",
    "    if len(psave_trinity_list)>0:\n",
    "        bashcommand_sourcepaths = ''\n",
    "        for p in psave_trinity_list:\n",
    "            p = \"'\"+p+\"'\"\n",
    "            bashcommand_sourcepaths += p\n",
    "            bashcommand_sourcepaths += ' '\n",
    "        bashcommand = 'cat ' + bashcommand_sourcepaths + '> ' + \"'\"+ psave_trinity + \"'\"\n",
    "        os.system(bashcommand)\n",
    "        # remove files\n",
    "        for p in psave_trinity_list:\n",
    "            os.remove(p)\n",
    "        print('\\tcombine slice processed trinity')\n",
    "\n",
    "    # load tirnity concatenated\n",
    "    df = pd.read_csv(psave_trinity, delim_whitespace=True, header=None, usecols=col_ind_keep, names=cnames_keep)\n",
    "    # check if wormid array are the same size as the concatenated array\n",
    "    if df.shape[0] == row_repeats_array.shape[0]:\n",
    "        # add wormid field\n",
    "        df['wormid'] = row_repeats_array\n",
    "        # into pickle\n",
    "        psave_pickle = os.path.join(pPlate, 'trinity_all_worms.pickle')\n",
    "        \n",
    "    else:\n",
    "        # print warning\n",
    "        array_dff = df.shape[0] - row_repeats_array.shape[0]\n",
    "        print(f'\\t!!wormid array has {array_dff} rows of the trinity data')\n",
    "        print(f'\\t!!save two data separately')\n",
    "        # name the df as no worm id\n",
    "        psave_pickle = os.path.join(pPlate, 'trinity_all_worms_nowormid.pickle')\n",
    "        # save worm id file\n",
    "        dfw = pd.DataFrame({'wormid': row_repeats_array})\n",
    "        # save\n",
    "        pickle.dump(dfw, open(os.path.join(dir_save,'trinity_all_worms_wormid_mismatch.pickle'),'wb'))\n",
    "\n",
    "\n",
    "    # save pickle\n",
    "    pickle.dump(df, open(psave_pickle,'wb'))\n",
    "    \n",
    "    # check if pickle file saved\n",
    "    if os.path.exists(psave_pickle):\n",
    "        # report size of the output\n",
    "        size_trinity = os.path.getsize(psave_pickle)\n",
    "        print(f'\\tsize of pickle file: {size_trinity/1000**2:.0f} MB')\n",
    "    else:\n",
    "        print('\\tpickle file did not save')\n",
    "    \n",
    "    # clean up temp files\n",
    "    if os.path.exists(psave_trinity):\n",
    "        print('\\tclean up trinity temp file')\n",
    "        os.remove(psave_trinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
