{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python361064bitdeeplearningconda6cab650cb5d443788736ce54d9cbc0f1",
      "display_name": "Python 3.6.10 64-bit ('deeplearning': conda)"
    },
    "colab": {
      "name": "NN_TensorFlow_nutcracker.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jKyRzFSf927",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2OSg5wXWvZL",
        "colab_type": "text"
      },
      "source": [
        "# NN for TensorFlow\n",
        "Conny Lin | June 18, 2020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMNCNNu4WvZP",
        "colab_type": "text"
      },
      "source": [
        "## Set up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb8-2WV3W1P7",
        "colab_type": "text"
      },
      "source": [
        "### Local computer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "LmhsZLY3WvZV",
        "colab_type": "code",
        "colab": {},
        "outputId": "a90faeee-2e5e-4e1f-ad89-312c69a8cede"
      },
      "source": [
        "# import local libraries using host specific paths\n",
        "import socket, sys\n",
        "hostname = socket.gethostname().split('.')[0]\n",
        "# set local path settings based on computer host\n",
        "if hostname == 'PFC':\n",
        "    pylibrary = '/Users/connylin/Dropbox/Code/proj'\n",
        "elif hostname == 'Angular-Gyrus':\n",
        "    pylibrary = '/Users/connylin/Code/proj'\n",
        "else:\n",
        "    assert False, 'host computer not regonized'\n",
        "# load local libraries\n",
        "if pylibrary not in sys.path:\n",
        "    sys.path.insert(1, pylibrary)\n",
        "# import other standard paths and local variables\n",
        "from brainstation_capstone.system import host_paths\n",
        "localpaths = host_paths.get(hostname)\n",
        "from brainstation_capstone.ml.toolbox.mlSOP import test_model\n",
        "from brainstation_capstone.ml.toolbox.mlSOP import ml_timer\n",
        "# import standard libraries\n",
        "import time, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# report latest run\n",
        "print(f'last ran on: {datetime.datetime.now()} PT')\n",
        "# import data\n",
        "from brainstation_capstone.etl.loaddata import nutcracker\n",
        "data = nutcracker(localpaths, 'nutcracker', ['X_train','X_test','y_train','y_test'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting host computer specific paths\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPnZi9-eW0lx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZxxYv5ZWvZk",
        "colab_type": "text"
      },
      "source": [
        "### Google Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mikVMfFfWvZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3c52f4a3-9a5c-478e-fa26-de727eceb429"
      },
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hgyveQdWvZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import functions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class test_model:\n",
        "    def __init__(self):\n",
        "        # set test and train score\n",
        "        self.test_acc = []\n",
        "        self.train_acc = []\n",
        "    def score_data(self, model, datadict):\n",
        "        self.model = model\n",
        "        self.data = datadict\n",
        "        # fit model\n",
        "        self.model.fit(self.data['X_train'], self.data['y_train'])\n",
        "        # train score\n",
        "        train_score = self.model.score(self.data['X_train'], self.data['y_train'])\n",
        "        print(f\"\\tTrain Score: {train_score}\")\n",
        "        self.train_acc.append(train_score)\n",
        "        # test score\n",
        "        test_score = self.model.score(self.data['X_test'], self.data['y_test'])\n",
        "        print(f\"\\tTest Score: {test_score}\")\n",
        "        self.test_acc.append(test_score)\n",
        "\n",
        "class ml_timer:\n",
        "    def __init__(self):\n",
        "        # initate session start time\n",
        "        self.start = time.time()\n",
        "        # initiate holder for times\n",
        "        self.session_times = []\n",
        "        print('timer starts')\n",
        "\n",
        "    def param_start(self):\n",
        "        # update current session start time\n",
        "        self.current_session_start = time.time()\n",
        "\n",
        "    def param_end(self):\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - self.current_session_start\n",
        "        print(f'\\telapsed time {elapsed_time/60:.3f} min')\n",
        "        self.session_times.append(elapsed_time)\n",
        "    \n",
        "    def session_end(self):\n",
        "        self.end = time.time()\n",
        "    \n",
        "    def get_time(self):\n",
        "        print(f'total time: {(self.end - self.start)/60:.3f} min')\n",
        "        return self.session_times\n",
        "\n",
        "def hyperparameterplot(hyperparameter_list, train_score_list, test_score_list, \\\n",
        "                        hyperparameter_name='', titlename=''):\n",
        "    \n",
        "    # check if hyperparameter list is string or number\n",
        "    if isinstance(hyperparameter_list[0], str):\n",
        "        hyperparameter_label = hyperparameter_list.copy()\n",
        "        hyperparameter_list = range(len(hyperparameter_list))\n",
        "    # graph\n",
        "    plt.figure()\n",
        "    plt.plot(hyperparameter_list, train_score_list, color='blue', label='train')\n",
        "    plt.plot(hyperparameter_list, test_score_list, color='red', label='test')\n",
        "    plt.title(titlename)\n",
        "    plt.xlabel(hyperparameter_name)\n",
        "    if isinstance(hyperparameter_list[0], str):\n",
        "        plt.xticks(labels=hyperparameter_label)\n",
        "    plt.ylabel('accuracy score')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aat0oV0AWvad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1ab28f41-4b7f-47d4-8721-cc39c4ce9afb"
      },
      "source": [
        "# define file directory\n",
        "file_dir = '/content/gdrive/My Drive/ED Brain Station/data'\n",
        "# get files from google drive\n",
        "print('loading data to data dictionary')\n",
        "datatype = ['X_train','X_test','y_train','y_test']\n",
        "dataname = 'nutcracker'\n",
        "data = dict()\n",
        "for i, dname in enumerate(datatype):\n",
        "    print(f'loading file: {i}', end='\\r')\n",
        "    filename = dataname + '_' + dname + '.csv'\n",
        "    filepath = os.path.join(file_dir, filename)\n",
        "    data[dname] = np.loadtxt(filepath, delimiter=',')\n",
        "print('loading completed')\n",
        "# print the array shape to confirm successful loading\n",
        "print(data['X_train'].shape)\n",
        "# report time run\n",
        "print(f'last ran on: {datetime.datetime.now()} PT')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data to data dictionary\n",
            "loading completed\n",
            "(1600000, 21)\n",
            "last ran on: 2020-06-20 20:13:17.602066 PT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Njz421Wvan",
        "colab_type": "text"
      },
      "source": [
        "# Explore the topic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czNX4sNVWvao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IqzbyL2WvbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create 100 fake data points\n",
        "fake_features = np.random.randn(100, 4)\n",
        "fake_target = np.eye(3)[np.random.choice(3, 100)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevO1agIYGwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2794532f-fe0c-4164-cedd-e7ba4a823d95"
      },
      "source": [
        "fake_features.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOSsgd-1Y41e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "6b08334c-8d11-42be-b7a5-9e4f3d876758"
      },
      "source": [
        "# define input and output size\n",
        "input_size = fake_features.shape[1]\n",
        "output_size = fake_target.shape[1]\n",
        "# Make the placeholder variables:\n",
        "input_X = tf.placeholder(tf.float32, shape=(None, input_size))\n",
        "input_y = tf.placeholder(tf.float32, shape=(None, output_size))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3fba489dd574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make the placeholder variables:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minput_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minput_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlCFb5c5gAUr",
        "colab_type": "text"
      },
      "source": [
        "Above doesn't work for some reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfuB7U0PhtHq",
        "colab_type": "text"
      },
      "source": [
        "## Keras\n",
        "\n",
        "tutorials: https://www.tensorflow.org/tutorials/structured_data/feature_columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpSt9zEKiPo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import feature_column\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYnMvU9Ih6n7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01cc03ee-e5f4-4079-dd0b-c1c5e3a767f7"
      },
      "source": [
        "input_shape = data['X_train'].shape[1]\n",
        "input_shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAYrs4Eihvex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1IpR9oEkZi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KZTAK4GkAsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "23e95178-0303-4348-c8b7-e008eedd3570"
      },
      "source": [
        "batch_size = 5 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(data['X_train'], batch_size=batch_size)\n",
        "val_ds = df_to_dataset(data['X_train'], shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(data['X_test'], shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ffe79f5b6a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;31m# A small batch sized is used for demonstration purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-2c1907456263>\u001b[0m in \u001b[0;36mdf_to_dataset\u001b[0;34m(dataframe, shuffle, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'pop'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23-3lqmlkBCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOq-zifhkBVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LAWpR_Uhpex",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch (move to another notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKFaJ7dBf1Gb",
        "colab_type": "text"
      },
      "source": [
        "Tutorial: https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1V0AatIf_lO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii5y6MFrZA8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su7Y4P8DgHyr",
        "colab_type": "text"
      },
      "source": [
        "**2. Define and intialize the neural network**\n",
        "\n",
        "Our network will recognize images. We will use a process built into PyTorch called convolution. Convolution adds each element of an image to its local neighbors, weighted by a kernel, or a small martrix, that helps us extract certain features (like edge detection, sharpness, blurriness, etc.) from the input image.\n",
        "\n",
        "There are two requirements for defining the Net class of your model. The first is writing an __init__ function that references nn.Module. This function is where you define the fully connected layers in your neural network.\n",
        "\n",
        "Using convolution, we will define our model to take 1 input image channel, and output match our target of 10 labels representing numbers 0 through 9. This algorithm is yours to create, we will follow a standard MNIST algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-qf4xokgDJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c768cba1-eb91-4160-9bb9-5b203ef84d8b"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      # First 2D convolutional layer, taking in 1 input channel (image),\n",
        "      # outputting 32 convolutional features, with a square kernel size of 3\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      # Second 2D convolutional layer, taking in the 32 input layers,\n",
        "      # outputting 64 convolutional features, with a square kernel size of 3\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "\n",
        "      # Designed to ensure that adjacent pixels are either all 0s or all active\n",
        "      # with an input probability\n",
        "      self.dropout1 = nn.Dropout2d(0.25)\n",
        "      self.dropout2 = nn.Dropout2d(0.5)\n",
        "\n",
        "      # First fully connected layer\n",
        "      self.fc1 = nn.Linear(9216, 128)\n",
        "      # Second fully connected layer that outputs our 10 labels\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "my_nn = Net()\n",
        "print(my_nn)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbdUCeOjgX8m",
        "colab_type": "text"
      },
      "source": [
        "**3. Specify how data will pass through your model**\n",
        "\n",
        "When you use PyTorch to build a model, you just have to define the forward function, that will pass the data into the computation graph (i.e. our neural network). This will represent our feed-forward algorithm.\n",
        "\n",
        "You can use any of the Tensor operations in the forward function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u16hwH0igXT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "      self.dropout1 = nn.Dropout2d(0.25)\n",
        "      self.dropout2 = nn.Dropout2d(0.5)\n",
        "      self.fc1 = nn.Linear(9216, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      # Pass data through conv1\n",
        "      x = self.conv1(x)\n",
        "      # Use the rectified-linear activation function over x\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = self.conv2(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      # Run max pooling over x\n",
        "      x = F.max_pool2d(x, 2)\n",
        "      # Pass data through dropout1\n",
        "      x = self.dropout1(x)\n",
        "      # Flatten x with start_dim=1\n",
        "      x = torch.flatten(x, 1)\n",
        "      # Pass data through fc1\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.dropout2(x)\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # Apply softmax to x\n",
        "      output = F.log_softmax(x, dim=1)\n",
        "      return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUZjixo9gkKr",
        "colab_type": "text"
      },
      "source": [
        "**4. [Optional] Pass data through your model to test**\n",
        "To ensure we receive our desired output, let’s test our model by passing some random data through it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0rkv9pNgjxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba056fb5-4df1-4fe6-dc5c-08822c5eaf25"
      },
      "source": [
        "# Equates to one random 28x28 image\n",
        "random_data = torch.rand((1, 1, 28, 28))\n",
        "\n",
        "my_nn = Net()\n",
        "result = my_nn(random_data)\n",
        "print (result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.3467, -2.3201, -2.3383, -2.3297, -2.4162, -2.3377, -2.1675, -2.3033,\n",
            "         -2.3289, -2.1661]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU426ZFYgroS",
        "colab_type": "text"
      },
      "source": [
        "Each number in this resulting tensor equates to the prediction of the label the random tensor is associated to.\n",
        "\n",
        "Congratulations! You have successfully defined a neural network in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qoey_-T8YkWj",
        "colab_type": "text"
      },
      "source": [
        "# Build simple tensor flow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PeQD8yrgi92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}