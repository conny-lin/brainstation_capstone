{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL trinity data\n",
    "# Conny Lin | June 4, 2020\n",
    "\n",
    "# prepare the data into machine learning ready format.\n",
    "# Extract data from individual plates, label with plate index in the plate db, and group name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global varialbes/paths\n",
    "dir_save = '/Users/connylin/Dropbox/CA/ED _20200119 Brain Station Data Science Diploma/Capstone/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make data db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file pickle\n",
    "plateDB = pickle.load(open(os.path.join(dir_save, 'file_summary_mwt.pickle'),'rb'))\n",
    "# get paths with trinity.id.dat\n",
    "pMWT = plateDB.index[~plateDB[('filepath','trinity.id.dat')].isna()].values\n",
    "del plateDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "MWTDB = pd.DataFrame({'mwtpath':pMWT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/871 files exist\n"
     ]
    }
   ],
   "source": [
    "# take a look at the db to see if any missing trinity pickle \n",
    "# instantiate \n",
    "report_capture = np.zeros(len(pMWT),dtype='bool')\n",
    "for plateid, pPlate in enumerate(MWTDB['mwtpath']):\n",
    "    # get expected apth to trinity data\n",
    "    pfile = os.path.join(pPlate, 'trinity_all_worms.pickle')\n",
    "    # see if file exist\n",
    "    if os.path.exists(pfile):\n",
    "        report_capture[plateid] = True\n",
    "    else:\n",
    "        print(f'{plateid} does not exist', end='\\r')\n",
    "\n",
    "# report result\n",
    "print(f'{np.sum(report_capture)}/{len(report_capture)} files exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the plate that failed to concatenate trinity\n",
    "MWTDB.drop(index=MWTDB.index[~report_capture].values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MWTDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add paths to trinitu files\n",
    "MWTDB['trinity_path'] = list(map(lambda x: os.path.join(x,'trinity_all_worms.pickle'), MWTDB['mwtpath']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "MWTDB.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract experiment features\n",
    "df = MWTDB['mwtpath'].str.split(pat='/', expand=True)\n",
    "MWTDB['expname'] = df.iloc[:,4]\n",
    "MWTDB['groupname'] = df.iloc[:,5]\n",
    "MWTDB['platename'] = df.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save database\n",
    "pickle.dump(MWTDB, open(os.path.join(dir_save, 'MWTDB_trinity_N2400mM.pickle'),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add labels to individual plate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plateid 869 dropped 7112 rows to 162496 rowssss\r"
     ]
    }
   ],
   "source": [
    "# take a sample to see if need per file processing\n",
    "for ind in MWTDB.index.values:\n",
    "    # get path\n",
    "    ptrinity = MWTDB['trinity_path'].iloc[ind]\n",
    "    # load to dataframe\n",
    "    df = pickle.load(open(ptrinity,'rb'))\n",
    "    row_n_original = df.shape[0]\n",
    "    # check if the data already been cleaned\n",
    "    if any(df.columns=='mwtid_trdb'):\n",
    "        continue\n",
    "    # clean nan data\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    row_n_after = df.shape[0]\n",
    "    print(f'plateid {ind} dropped {row_n_original - row_n_after} rows to {row_n_after} rows', end='\\r')\n",
    "    # add file path \n",
    "    df.insert(0,'mwtid_trdb', np.tile(MWTDB.index[ind], df.shape[0]))\n",
    "    # add group id (ethanol=1 vs no ethanol=0)\n",
    "    if MWTDB['groupname'][ind]=='N2':\n",
    "        df.insert(1,'etoh', np.tile(0, df.shape[0]))\n",
    "    else:\n",
    "        df.insert(1,'etoh', np.tile(1, df.shape[0]))\n",
    "    # save the file\n",
    "    pickle.dump(df, open(ptrinity,'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat all trinity data\n",
    "https://stackoverflow.com/questions/56012595/how-to-pickle-multiple-pandas-dataframes-and-concatenate-all-of-them-i\n",
    "\n",
    "```\n",
    "df = pd.concat([pd.read_pickle('/PATH/df/{}/{}.F.K.df'.format('train', f)).iloc[:, :100] \n",
    "                for f in Files], \n",
    "               axis=1)\n",
    "```\n",
    "\n",
    "`a = [pd.read_pickle(p) for p in MWTDB['trinity_path'][:10]]`\n",
    "\n",
    "Issues:\n",
    "\n",
    "* Each csv is ~100MB * 800 = 80GB csv. My computer won't be able to open this file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at  behavior and see if can predict which tap it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
