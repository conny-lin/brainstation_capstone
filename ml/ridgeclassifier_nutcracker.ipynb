{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "ridgeclassifier_nutcracker.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Az_NmBcwC5",
        "colab_type": "text"
      },
      "source": [
        "# RidgeClassifier\n",
        "Conny Lin | June 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxB9xlfBc1oo",
        "colab_type": "text"
      },
      "source": [
        "## set up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QuHR4Fpc1zf",
        "colab_type": "text"
      },
      "source": [
        "## local computer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letQgGIFcqvo",
        "colab_type": "code",
        "colab": {},
        "outputId": "4ce18c4e-a2d0-4e0f-a47a-561ff1e032a9"
      },
      "source": [
        "# import local libraries using host specific paths\n",
        "import socket, sys, time, datetime, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# get paths for local computer\n",
        "hostname = socket.gethostname().split('.')[0]\n",
        "# set local path settings based on computer host\n",
        "if hostname == 'PFC':\n",
        "    pylibrary = '/Users/connylin/Dropbox/Code/proj'\n",
        "elif hostname == 'Angular-Gyrus':\n",
        "    pylibrary = '/Users/connylin/Code/proj'\n",
        "else:\n",
        "    assert False, 'host computer not regonized'\n",
        "\n",
        "# import local variables\n",
        "if pylibrary not in sys.path:\n",
        "    sys.path.insert(1, pylibrary)\n",
        "from brainstation_capstone.ml.toolbox.mlSOP import test_model\n",
        "from brainstation_capstone.ml.toolbox.mlSOP import ml_timer\n",
        "from brainstation_capstone.ml.toolbox.mlSOP import ModelEvaluation\n",
        "from brainstation_capstone.system import host_paths\n",
        "localpaths = host_paths.get(hostname)\n",
        "data_dir = os.path.join(localpaths['Capstone'], 'data')\n",
        "\n",
        "# report latest run\n",
        "print(f'last ran on: {datetime.datetime.now()} PT')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting host computer specific paths\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sccnkpq8c8FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import data\n",
        "from brainstation_capstone.etl.loaddata import nutcracker\n",
        "data = nutcracker(localpaths, 'nutcracker', ['X_train','X_test','y_train','y_test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HqI1wKMct-6",
        "colab_type": "text"
      },
      "source": [
        "### google colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGcuBunldALS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "22a657a2-88b3-4fad-99a2-b56943b4a30a"
      },
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMgJYwyadASz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34fd73c6-5860-49fb-efb2-4dd5b2b6ea4c"
      },
      "source": [
        "# import functions and data\n",
        "print('import functions')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# define file directory\n",
        "data_dir = '/content/gdrive/My Drive/ED Brain Station/data'\n",
        "\n",
        "class test_model:\n",
        "    def __init__(self):\n",
        "        # set test and train score\n",
        "        self.test_acc = []\n",
        "        self.train_acc = []\n",
        "    def score_data(self, model, datadict):\n",
        "        self.model = model\n",
        "        self.data = datadict\n",
        "        # fit model\n",
        "        self.model.fit(self.data['X_train'], self.data['y_train'])\n",
        "        # train score\n",
        "        train_score = self.model.score(self.data['X_train'], self.data['y_train'])\n",
        "        print(f\"\\tTrain Score: {train_score}\")\n",
        "        self.train_acc.append(train_score)\n",
        "        # test score\n",
        "        test_score = self.model.score(self.data['X_test'], self.data['y_test'])\n",
        "        print(f\"\\tTest Score: {test_score}\")\n",
        "        self.test_acc.append(test_score)\n",
        "\n",
        "class ml_timer:\n",
        "    def __init__(self):\n",
        "        # initate session start time\n",
        "        self.start = time.time()\n",
        "        # initiate holder for times\n",
        "        self.session_times = []\n",
        "        print('timer starts')\n",
        "\n",
        "    def param_start(self):\n",
        "        # update current session start time\n",
        "        self.current_session_start = time.time()\n",
        "\n",
        "    def param_end(self):\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - self.current_session_start\n",
        "        print(f'\\telapsed time {elapsed_time/60:.3f} min')\n",
        "        self.session_times.append(elapsed_time)\n",
        "    \n",
        "    def session_end(self):\n",
        "        self.end = time.time()\n",
        "    \n",
        "    def get_time(self):\n",
        "        print(f'total time: {(self.end - self.start)/60:.3f} min')\n",
        "        return self.session_times\n",
        "\n",
        "def hyperparameterplot(hyperparameter_list, train_score_list, test_score_list, \\\n",
        "                        hyperparameter_name='', xscale='linear', titlename=''):\n",
        "    # check if hyperparameter list is string or number\n",
        "    if isinstance(hyperparameter_list[0], str):\n",
        "        hyperparameter_label = hyperparameter_list.copy()\n",
        "        hyperparameter_list = range(len(hyperparameter_list))\n",
        "    # graph\n",
        "    plt.figure()\n",
        "    plt.plot(hyperparameter_list, train_score_list, color='blue', label='train')\n",
        "    plt.plot(hyperparameter_list, test_score_list, color='red', label='test')\n",
        "    plt.title(titlename)\n",
        "    plt.xlabel(hyperparameter_name)\n",
        "    if isinstance(hyperparameter_list[0], str):\n",
        "        plt.xticks(labels=hyperparameter_label)\n",
        "    plt.ylabel('accuracy score')\n",
        "    plt.xscale(xscale)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def load_nutcracker_csv(dir_datafolder):\n",
        "    datatype = ['X_train','X_test','y_train','y_test']\n",
        "    print(f'loading {len(datatype)} files')\n",
        "    datadict = dict()\n",
        "    for i, dname in enumerate(datatype):\n",
        "        print(f'loading file: {i}', end='\\r')\n",
        "        filename = 'nutcracker' + '_' + dname + '.csv'\n",
        "        filepath = os.path.join(dir_datafolder, filename)\n",
        "        data = pd.read_csv(filepath, header=None, index_col=False)\n",
        "        datadict[dname] = data.to_numpy()\n",
        "    print('\\nloading completed')\n",
        "    return datadict\n",
        "\n",
        "\n",
        "\n",
        "class ModelEvaluation:\n",
        "    def __init__(self, model, data_dir):\n",
        "        self.model = model\n",
        "        self.data_dir = data_dir\n",
        "    \n",
        "    def load_data(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.data = load_nutcracker_csv(self.data_dir)\n",
        "\n",
        "    def cross_val_score(self, cv=5):\n",
        "        timer = ml_timer()\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()\n",
        "        from sklearn.model_selection import cross_val_score\n",
        "        scores = cross_val_score(self.model, \n",
        "                    self.data['X_train'], \n",
        "                    self.data['y_train'], \n",
        "                    cv=cv)\n",
        "        timer.session_end()\n",
        "        self.runtime_crossval = timer.get_time()\n",
        "        print(f'cross validation scores: {scores}')\n",
        "        print(f'validation score (mean):{np.mean(scores)}')\n",
        "        print(f'validation score (std):{np.std(scores)}')\n",
        "        self.cross_val_score_ = scores\n",
        "        return self.cross_val_score_\n",
        "    \n",
        "    def fitmodel(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()\n",
        "        self.model.fit(self.data['X_train'], self.data['y_train'])\n",
        "        return self.model\n",
        "    \n",
        "    def predict(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()\n",
        "        timer = ml_timer()\n",
        "        self.y_pred_test = self.model.predict(self.data['X_test'])\n",
        "        timer.session_end()\n",
        "        self.runtime_predict = timer.get_time()\n",
        "        self.y_pred_train = self.model.predict(self.data['X_train'])\n",
        "\n",
        "    def accuracy_score(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()\n",
        "        self.score_train = self.model.score(self.data[\"X_train\"], self.data['y_train'])\n",
        "        print(f'accuracy score on train: {self.score_train}')\n",
        "        self.score_test = self.model.score(self.data['X_test'], self.data['y_test'])\n",
        "        print(f'accuracy score on test: {self.score_test}')\n",
        "        return self.score_train, self.score_test\n",
        "\n",
        "    def confusion_matrix(self):\n",
        "        if not hasattr(self, 'y_pred_test'):\n",
        "            self.predict()\n",
        "        # fitmodel and predict must proceed this.\n",
        "        # define dataframe labels\n",
        "        columns = ['Predicted normal', 'Predicted alcohol']\n",
        "        indexname = ['True normal', 'True alcohol']\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        # run confusion matrix - test\n",
        "        self.conf_matrix_test = confusion_matrix(self.data['y_test'], self.y_pred_test, \n",
        "                                            normalize='true')\n",
        "        conf_matrix_test_df = pd.DataFrame(self.conf_matrix_test, columns=columns)\n",
        "        conf_matrix_test_df.index = indexname\n",
        "        print('\\nconfusion matrix: test data')\n",
        "        print(conf_matrix_test_df)\n",
        "        # run confusion matrix - train\n",
        "        self.conf_matrix_train = confusion_matrix(self.data['y_train'], \n",
        "                                            self.y_pred_train, \n",
        "                                            normalize='true')\n",
        "        conf_matrix_train_df = pd.DataFrame(self.conf_matrix_train, columns=columns)\n",
        "        conf_matrix_train_df.index = indexname\n",
        "        print('\\nconfusion matrix: train data')\n",
        "        print(conf_matrix_train_df)\n",
        "        return self.conf_matrix_test, self.conf_matrix_train\n",
        "    \n",
        "    def display_confusion_matrix(self):\n",
        "        if not hasattr(self, 'conf_matrix_test'):\n",
        "            self.confusion_matrix()\n",
        "        # confusion_matrix must proceed this\n",
        "        display_labels = ['normal', 'alcohol']\n",
        "        from sklearn.metrics import ConfusionMatrixDisplay\n",
        "        print('\\nconfusion matrix for test')\n",
        "        plt.figure()\n",
        "        ConfusionMatrixDisplay(self.conf_matrix_test, display_labels=display_labels).plot()\n",
        "        plt.show()\n",
        "        print('\\nconfusion matrix for train')\n",
        "        plt.figure()\n",
        "        ConfusionMatrixDisplay(self.conf_matrix_train, display_labels=display_labels).plot()\n",
        "        plt.show()\n",
        "\n",
        "    def classification_report(self):\n",
        "        if not hasattr(self, 'y_pred_test'):\n",
        "            self.predict()\n",
        "        from sklearn.metrics import classification_report\n",
        "        self.eval_score_report = classification_report(self.data['y_test'], \n",
        "                                                        self.y_pred_test)\n",
        "        print(self.eval_score_report)\n",
        "    \n",
        "    def print_evaluation_scores(self):\n",
        "        if not hasattr(self, 'y_pred_test'):\n",
        "            self.predict()        \n",
        "        from sklearn.metrics import precision_score\n",
        "        from sklearn.metrics import recall_score\n",
        "        from sklearn.metrics import f1_score\n",
        "        self.precision_score = precision_score(self.data[\"y_test\"], self.y_pred_test)\n",
        "        self.recall_score = recall_score(self.data[\"y_test\"], self.y_pred_test)\n",
        "        self.f1_score = f1_score(self.data[\"y_test\"], self.y_pred_test)\n",
        "        print(f'precision_score = {self.precision_score}')\n",
        "        print(f'recall_score = {self.recall_score}')\n",
        "        print(f'f1_score = {self.f1_score}')\n",
        "    \n",
        "    def test_data_class_proba(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()        \n",
        "        false_proba = np.count_nonzero(self.data['y_test']) / self.data['y_test'].shape[0]\n",
        "        true_proba = 1.0 - false_proba\n",
        "        print(f'test set normal case probability: {false_proba}')\n",
        "        print(f'test set alcohol case probability: {true_proba}')\n",
        "        self.real_proba = dict()\n",
        "        self.real_proba['false_proba'] = false_proba\n",
        "        self.real_proba['true_proba'] = true_proba\n",
        "    \n",
        "    def predict_proba(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()\n",
        "        self.y_proba_test = self.model.predict_proba(self.data['X_test'])[:,1]\n",
        "        self.y_proba_train = self.model.predict_proba(self.data['X_train'])[:,1]\n",
        "        return self.y_proba_test, self.y_proba_train\n",
        "\n",
        "    def proba_thresholds(self):\n",
        "        if not hasattr(self, 'data'):\n",
        "            self.load_data()\n",
        "        from sklearn.metrics import accuracy_score\n",
        "        from sklearn.metrics import precision_score\n",
        "        from sklearn.metrics import recall_score\n",
        "        # Vary thresholds by 0.05 from 0.05 to 0.95\n",
        "        thresholds = np.arange(0.05, 1, 0.05)\n",
        "        precisions = list()\n",
        "        recalls = list()\n",
        "        neg_recalls = list()\n",
        "        for threshold in thresholds:\n",
        "            # Apply threshold\n",
        "            y_threshold = np.where(self.y_proba_test > threshold, 1, 0)\n",
        "            # Calculate precision and recall\n",
        "            precision = precision_score(self.data['y_test'], y_threshold)\n",
        "            recall = recall_score(self.data['y_test'], y_threshold)\n",
        "            neg_recall = recall_score(1-self.data['y_test'], 1-y_threshold)\n",
        "            # Append to list\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            neg_recalls.append(neg_recall)\n",
        "        # Visualize the result\n",
        "        plt.figure()\n",
        "        plt.plot(thresholds, precisions, label='precision', marker='o')\n",
        "        plt.plot(thresholds, recalls, label='recall', marker='o')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.xlabel('threshold')\n",
        "        plt.ylabel('score')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        return precisions, recalls, neg_recalls\n",
        "        \n",
        "    def roc_auc(self):\n",
        "        if hasattr(self, 'y_proba_train'):\n",
        "            self.predict_proba()\n",
        "        from sklearn.metrics import roc_curve, roc_auc_score\n",
        "        # get roc auc train\n",
        "        fprs_train, tprs_train, thresholds_train = roc_curve(self.data['y_train'], self.y_proba_train)\n",
        "        roc_auc_train = roc_auc_score(self.data['y_train'], self.y_proba_train)\n",
        "        # get roc auc test\n",
        "        fprs_test, tprs_test, thresholds_test = roc_curve(self.data['y_test'], self.y_proba_test)\n",
        "        roc_auc_test = roc_auc_score(self.data['y_test'], self.y_proba_test)\n",
        "        # Plot the ROC curve.\n",
        "        plt.figure()\n",
        "        plt.plot(fprs_train, tprs_train, color='gray', lw=5, label='train', linestyle=' ', marker='.')\n",
        "        plt.plot(fprs_test, tprs_test, lw=1, color='red', label='test')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='expected')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC and AUC')\n",
        "        plt.legend(loc=\"best\")\n",
        "        plt.show()\n",
        "        print(f\"Test AUC score: {roc_auc_test}\")\n",
        "        print(f\"Train AUC score: {roc_auc_train}\")\n",
        "        self.roc_auc_test = roc_auc_test\n",
        "        self.roc_auc_train = roc_auc_train\n",
        "    \n",
        "    def save(self, savedir):\n",
        "        # remove data from object to save space\n",
        "        if hasattr(self, 'data'):\n",
        "            delattr(self, 'data')\n",
        "        if hasattr(self, 'y_pred_test'):\n",
        "            delattr(self, 'y_pred_test')\n",
        "        if hasattr(self, 'y_pred_train'):\n",
        "            delattr(self, 'y_pred_train')\n",
        "        if hasattr(self, 'y_proba_test'):\n",
        "            delattr(self, 'y_proba_test') \n",
        "        if hasattr(self, 'y_proba_train'):\n",
        "            delattr(self, 'y_proba_train') \n",
        "        # get model name\n",
        "        model_type = type(self.model)\n",
        "        model_type_str  = str(model_type)\n",
        "        model_name_components = model_type_str.split('.')\n",
        "        model_name = model_name_components[-1].replace(\"'>\",\"\")\n",
        "        # save\n",
        "        import pickle, os\n",
        "        savepath = os.path.join(savedir, model_name+'_eval.pickle')\n",
        "        pickle.dump(self, open(savepath, 'wb'))\n",
        "\n",
        "    def excel_input_array(self):\n",
        "        # TODO: write input validation code\n",
        "        report = [np.mean(self.cross_val_score_),\n",
        "                    np.std(self.cross_val_score_),\n",
        "                    self.score_train,\n",
        "                    self.score_test,\n",
        "                    self.precision_score,\n",
        "                    self.recall_score,\n",
        "                    self.f1_score,\n",
        "                    self.roc_auc_train,\n",
        "                    self.roc_auc_test,\n",
        "                    self.runtime_crossval,\n",
        "                    self.runtime_predict]\n",
        "        print(report)\n",
        "        print(self.model)\n",
        "    \n",
        "    def standard(self, save_dir):\n",
        "        print('\\nloading data from directory')\n",
        "        self.load_data()\n",
        "        print('\\nruning cross validation scores (this takes a while):')\n",
        "        self.cross_val_score(5)\n",
        "        print('\\nfit model...')\n",
        "        self.fitmodel()\n",
        "        print('predict model...')\n",
        "        self.predict()\n",
        "        print('\\naccuracy scores:')\n",
        "        self.accuracy_score()\n",
        "        print('\\nconfusion matrix:')\n",
        "        self.confusion_matrix()\n",
        "        self.display_confusion_matrix()\n",
        "        print('\\nclassification report:')\n",
        "        self.classification_report()\n",
        "        self.print_evaluation_scores()\n",
        "        if hasattr(self, 'predict_proba'):\n",
        "            print('\\nreal data class proba:')\n",
        "            self.test_data_class_proba()\n",
        "            print('\\n prediction proba:')\n",
        "            self.predict_proba()\n",
        "            print('\\nproba threshold analysis:')\n",
        "            self.proba_thresholds()\n",
        "            print('\\nROC AUC analysis:')\n",
        "            self.roc_auc()\n",
        "            print('\\nSaving model...')\n",
        "        else:\n",
        "            print('\\nthis model does not have predict_proba attr')\n",
        "        self.save(save_dir)\n",
        "        print('\\nexcel record:')\n",
        "        self.excel_input_array()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import functions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDXINs_ldAYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get files from google drive\n",
        "print('loading data to data dictionary')\n",
        "datatype = ['X_train','X_test','y_train','y_test']\n",
        "dataname = 'nutcracker'\n",
        "data = dict()\n",
        "for i, dname in enumerate(datatype):\n",
        "    print(f'loading file: {i}', end='\\r')\n",
        "    filename = dataname + '_' + dname + '.csv'\n",
        "    filepath = os.path.join(file_dir, filename)\n",
        "    data[dname] = np.loadtxt(filepath, delimiter=',')\n",
        "print('loading completed')\n",
        "# print the array shape to confirm successful loading\n",
        "print(data['X_train'].shape)\n",
        "# report time run\n",
        "print(f'last ran on: {datetime.datetime.now()} PT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG_JHFp5cu3o",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c2W7YHwcqvt",
        "colab_type": "text"
      },
      "source": [
        "## no tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gth0E9Kcqvu",
        "colab_type": "text"
      },
      "source": [
        "no feature reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Ao695ldh_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFp15vUPcqvu",
        "colab_type": "code",
        "colab": {},
        "outputId": "1ee72a0c-8ad0-4892-daab-a1e3d84c9acb"
      },
      "source": [
        "# get machine learning input data\n",
        "from brainstation_capstone.etl.datatransform import Nutcracker\n",
        "X_train, X_test, y_train, y_test = Nutcracker(localpaths['datapath']).mldata(feature_reduction='None')\n",
        "print(f'X has {X_train.shape[1]} features')\n",
        "# run untuned model\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "clf = RidgeClassifier().fit(X_train, y_train)\n",
        "testscore_fullfeature = clf.score(X_test, y_test)\n",
        "trainscore_fullfeature = clf.score(X_train, y_train)\n",
        "print(f'test score: {testscore_fullfeature}')\n",
        "print(f'train score: {trainscore_fullfeature}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "X has 21 features\n",
            "test score: 0.8664475\n",
            "train score: 0.866919375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFKHjtjPcqvx",
        "colab_type": "text"
      },
      "source": [
        "reduced to 18 features (remove time, persistence, and orient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BITQSZtcqvy",
        "colab_type": "code",
        "colab": {},
        "outputId": "975a812c-7903-46c7-a862-80c32b1f58c2"
      },
      "source": [
        "# get machine learning input data\n",
        "from brainstation_capstone.etl.datatransform import Nutcracker\n",
        "X_train, X_test, y_train, y_test = Nutcracker(localpaths['datapath']).mldata(feature_reduction='standard')\n",
        "print(f'X has {X_train.shape[1]} features')\n",
        "# run untuned model\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "clf = RidgeClassifier().fit(X_train, y_train)\n",
        "testscore_18feature = clf.score(X_test, y_test)\n",
        "trainscore_18feature = clf.score(X_train, y_train)\n",
        "print(f'test score: {testscore_fullfeature}')\n",
        "print(f'train score: {trainscore_fullfeature}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "standard\n",
            "X has 18 features\n",
            "test score: 0.8664475\n",
            "train score: 0.866919375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz8rCnEYcqv2",
        "colab_type": "code",
        "colab": {},
        "outputId": "9cc30cfc-50fe-4f7e-c568-9932914c15c7"
      },
      "source": [
        "# comparison of full vs 18 features\n",
        "train_feature_reduction_acc_gain = trainscore_18feature - trainscore_fullfeature\n",
        "test_feature_reduction_acc_gain = testscore_18feature - testscore_fullfeature\n",
        "print(f'reduce to 18 feature accuracy gain (train): {train_feature_reduction_acc_gain*100:.3f}%')\n",
        "print(f'reduce to 18 feature accuracy gain (test): {test_feature_reduction_acc_gain*100:.3f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reduce to 18 feature accuracy gain (train): -0.216%\n",
            "reduce to 18 feature accuracy gain (test): -0.218%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A2YMKVxcqv6",
        "colab_type": "text"
      },
      "source": [
        "reducing 18 features loses accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnb5hgHcqv6",
        "colab_type": "text"
      },
      "source": [
        "## tune alpha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoWB8HY1cqv7",
        "colab_type": "code",
        "colab": {},
        "outputId": "dde43a28-5c89-4217-ceff-f111874716b2"
      },
      "source": [
        "# example of grid searching key hyperparametres for ridge classifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "# import data\n",
        "X_train, _, y_train, _ = Nutcracker(datapath).mldata(feature_reduction='None')\n",
        "\n",
        "# define models and parameters\n",
        "model = RidgeClassifier()\n",
        "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "cv = 5 #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# define grid search\n",
        "grid = dict(alpha=alpha)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, \n",
        "                           cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "from brainstation_capstone.ml import GridSearchCVHelper\n",
        "mean, stdev, param = GridSearchCVHelper.print_summary(grid_result)\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "Best: 0.864768 using {'alpha': 0.7}\n",
            "0.864767 (0.000452) with: {'alpha': 0.1}\n",
            "0.864767 (0.000452) with: {'alpha': 0.2}\n",
            "0.864767 (0.000452) with: {'alpha': 0.3}\n",
            "0.864767 (0.000452) with: {'alpha': 0.4}\n",
            "0.864767 (0.000452) with: {'alpha': 0.5}\n",
            "0.864767 (0.000452) with: {'alpha': 0.6}\n",
            "0.864768 (0.000451) with: {'alpha': 0.7}\n",
            "0.864768 (0.000451) with: {'alpha': 0.8}\n",
            "0.864768 (0.000451) with: {'alpha': 0.9}\n",
            "0.864768 (0.000451) with: {'alpha': 1.0}\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-BjprRzcqv-",
        "colab_type": "text"
      },
      "source": [
        "not much difference with different alpha. try different solve and set random state to 318"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEG6TbVkehNJ",
        "colab_type": "text"
      },
      "source": [
        "## tune alpha plus solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adLHOEEYcqv_",
        "colab_type": "code",
        "colab": {},
        "outputId": "6218072a-c6b3-46c3-fe3d-1205a1e7cde4"
      },
      "source": [
        "# example of grid searching key hyperparametres for ridge classifier\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "# import data\n",
        "from brainstation_capstone.etl.datatransform import Nutcracker\n",
        "X_train, _, y_train, _ = Nutcracker(datapath).mldata(feature_reduction='None')\n",
        "\n",
        "# define models and parameters\n",
        "model = RidgeClassifier()\n",
        "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "solver = ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
        "random_state = [318]\n",
        "\n",
        "grid = dict(alpha=alpha, solver=solver, random_state=random_state)\n",
        "\n",
        "# grid search setting\n",
        "cv = 5 #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, \n",
        "                           cv=cv, scoring='accuracy',error_score=0)\n",
        "# run gridsearch\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "from brainstation_capstone.ml import GridSearchCVHelper\n",
        "mean, stdev, param = GridSearchCVHelper.print_summary(grid_result)\n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "Best: 0.866908 using {'alpha': 0.1, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.1, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.1, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866898 (0.000456) with: {'alpha': 0.1, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866902 (0.000439) with: {'alpha': 0.1, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866908 (0.000451) with: {'alpha': 0.1, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866906 (0.000441) with: {'alpha': 0.1, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.2, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.2, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866898 (0.000457) with: {'alpha': 0.2, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866903 (0.000440) with: {'alpha': 0.2, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866908 (0.000451) with: {'alpha': 0.2, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866905 (0.000442) with: {'alpha': 0.2, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.3, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.3, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000457) with: {'alpha': 0.3, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866901 (0.000439) with: {'alpha': 0.3, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866907 (0.000450) with: {'alpha': 0.3, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866905 (0.000442) with: {'alpha': 0.3, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.4, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.4, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 0.4, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866902 (0.000439) with: {'alpha': 0.4, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866907 (0.000450) with: {'alpha': 0.4, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866905 (0.000442) with: {'alpha': 0.4, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.5, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.5, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 0.5, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866900 (0.000438) with: {'alpha': 0.5, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866907 (0.000450) with: {'alpha': 0.5, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866905 (0.000442) with: {'alpha': 0.5, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.6, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.6, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 0.6, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866901 (0.000439) with: {'alpha': 0.6, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866907 (0.000450) with: {'alpha': 0.6, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866905 (0.000442) with: {'alpha': 0.6, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.7, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.7, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 0.7, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866901 (0.000439) with: {'alpha': 0.7, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866908 (0.000450) with: {'alpha': 0.7, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866906 (0.000442) with: {'alpha': 0.7, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.8, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.8, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 0.8, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866901 (0.000439) with: {'alpha': 0.8, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866908 (0.000450) with: {'alpha': 0.8, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866906 (0.000442) with: {'alpha': 0.8, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.9, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 0.9, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 0.9, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866901 (0.000439) with: {'alpha': 0.9, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866908 (0.000450) with: {'alpha': 0.9, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866906 (0.000442) with: {'alpha': 0.9, 'random_state': 318, 'solver': 'saga'}\n",
            "0.866904 (0.000446) with: {'alpha': 1.0, 'random_state': 318, 'solver': 'svd'}\n",
            "0.866904 (0.000446) with: {'alpha': 1.0, 'random_state': 318, 'solver': 'cholesky'}\n",
            "0.866897 (0.000458) with: {'alpha': 1.0, 'random_state': 318, 'solver': 'lsqr'}\n",
            "0.866901 (0.000439) with: {'alpha': 1.0, 'random_state': 318, 'solver': 'sparse_cg'}\n",
            "0.866908 (0.000450) with: {'alpha': 1.0, 'random_state': 318, 'solver': 'sag'}\n",
            "0.866906 (0.000442) with: {'alpha': 1.0, 'random_state': 318, 'solver': 'saga'}\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfM_9Fmrdavy",
        "colab_type": "text"
      },
      "source": [
        "## final eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw45DqR7dbmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "22e68876-dbbf-4d1a-fa67-b71c0703559f"
      },
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "model = RidgeClassifier(random_state=318, alpha=0.1, solver='sag')\n",
        "save_dir = os.path.join(data_dir, 'ml_eval_results')\n",
        "model_eval = ModelEvaluation(model, data_dir)\n",
        "model_eval.standard(save_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "loading data from directory\n",
            "loading 4 files\n",
            "\n",
            "loading completed\n",
            "\n",
            "runing cross validation scores (this takes a while):\n",
            "timer starts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_ridge.py:940: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1fQUcSfIlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}